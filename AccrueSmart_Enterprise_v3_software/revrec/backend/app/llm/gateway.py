# backend/app/llm/gateway.py
from __future__ import annotations
import os
import json
from typing import Dict, Any, Optional

class LLMGateway:
    """
    Gateway for LLM operations - supports both mock and real LLM providers.
    Set LLM_PROVIDER environment variable to enable real LLM calls.
    """
    
    def __init__(self):
        self.provider = os.getenv("LLM_PROVIDER", "mock")
        self.api_key = os.getenv("OPENAI_API_KEY") or os.getenv("ANTHROPIC_API_KEY")
        
    def audit_memo(self, payload: Dict[str, Any]) -> str:
        """
        Generate an audit memo based on the provided context.
        
        Args:
            payload: Dictionary with context information (contract_id, schedules, risks, etc.)
            
        Returns:
            str: Generated audit memo text
        """
        if self.provider == "mock":
            return self._mock_audit_memo(payload)
        elif self.provider == "openai":
            return self._openai_audit_memo(payload)
        elif self.provider == "anthropic":
            return self._anthropic_audit_memo(payload)
        else:
            return self._mock_audit_memo(payload)
    
    def _mock_audit_memo(self, payload: Dict[str, Any]) -> str:
        """Generate a mock audit memo for development/testing"""
        contract_id = payload.get("contract_id", "UNKNOWN")
        customer = payload.get("customer", "N/A")
        
        memo = f"""
AUDIT MEMO
Contract: {contract_id}
Customer: {customer}
Date: {self._get_current_date()}

EXECUTIVE SUMMARY:
This memo summarizes the key audit findings and compliance status for the referenced contract.

REVENUE RECOGNITION ASSESSMENT:
- Contract structure appears compliant with ASC 606
- Performance obligations properly identified
- Transaction price allocation follows relative SSP methodology

"""
        if "stats" in payload:
            stats = payload["stats"]
            memo += f"""
JOURNAL ENTRY STATISTICS:
- Total Journals: {stats.get('total_journals', 0)}
- Posted: {stats.get('posted_journals', 0)}
- Pending: {stats.get('unposted_journals', 0)}
"""
        
        if "anomalies" in payload:
            anomalies = payload.get("anomalies", [])
            if anomalies:
                memo += "ANOMALIES DETECTED:\n"
                for anomaly in anomalies:
                    memo += f"- {anomaly}\n"
                memo += "\n"
            else:
                memo += "No significant anomalies detected.\n\n"
        
        if "modules" in payload:
            modules = payload.get("modules", [])
            memo += f"MODULES ANALYZED: {', '.join(modules)}\n\n"
        
        memo += """
RECOMMENDATIONS:
1. Continue monitoring for compliance with established policies
2. Review any flagged anomalies with appropriate stakeholders
3. Maintain proper documentation for audit trail purposes

CONCLUSION:
Based on the analysis performed, the contract and related transactions appear to be
in substantial compliance with applicable accounting standards and internal policies.

---
This memo was generated by AuditWise AI
"""
        return memo.strip()
    
    def _openai_audit_memo(self, payload: Dict[str, Any]) -> str:
        """Generate audit memo using OpenAI API"""
        try:
            import openai
            
            openai.api_key = self.api_key
            
            prompt = self._build_audit_prompt(payload)
            
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are an expert financial auditor creating comprehensive audit memos."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"OpenAI API error: {e}")
            return self._mock_audit_memo(payload)
    
    def _anthropic_audit_memo(self, payload: Dict[str, Any]) -> str:
        """Generate audit memo using Anthropic API"""
        try:
            import anthropic
            
            client = anthropic.Anthropic(api_key=self.api_key)
            
            prompt = self._build_audit_prompt(payload)
            
            message = client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1500,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            return message.content[0].text
            
        except Exception as e:
            print(f"Anthropic API error: {e}")
            return self._mock_audit_memo(payload)
    
    def _build_audit_prompt(self, payload: Dict[str, Any]) -> str:
        """Build a prompt for LLM audit memo generation"""
        prompt = f"""
Create a professional audit memo based on the following information:

Contract ID: {payload.get('contract_id', 'N/A')}
Customer: {payload.get('customer', 'N/A')}
"""
        
        if "stats" in payload:
            prompt += f"\nJournal Statistics: {json.dumps(payload['stats'], indent=2)}"
        
        if "anomalies" in payload:
            prompt += f"\nAnomalies: {json.dumps(payload['anomalies'], indent=2)}"
        
        if "modules" in payload:
            prompt += f"\nModules Analyzed: {', '.join(payload['modules'])}"
        
        prompt += """

Please provide:
1. Executive summary
2. Assessment of revenue recognition compliance
3. Analysis of any anomalies
4. Recommendations
5. Conclusion

Format as a professional audit memo.
"""
        return prompt
    
    @staticmethod
    def _get_current_date() -> str:
        """Get current date in YYYY-MM-DD format"""
        from datetime import date
        return date.today().isoformat()